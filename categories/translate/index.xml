<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Translate on Stein&#39;s World</title>
    <link>https://steinliber.github.io/categories/translate/index.xml</link>
    <description>Recent content in Translate on Stein&#39;s World</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="https://steinliber.github.io/categories/translate/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>在线进行大规模的数据迁移[译]</title>
      <link>https://steinliber.github.io/post/online-migrations/</link>
      <pubDate>Fri, 24 Feb 2017 13:50:46 +0200</pubDate>
      
      <guid>https://steinliber.github.io/post/online-migrations/</guid>
      <description>

&lt;p&gt;工程师团队在构建软件时会面临一个普遍的挑战：为了支持整洁的抽象和愈加复杂的特性，他们通常需要重新设计所使用的数据模型。在生产环境中，这或许就意味着要迁移百万级的活跃对象和重构数千行的代码。&lt;/p&gt;

&lt;p&gt;Stripe 的用户期望我们的接口是可用并且一致的。这就意味着当我们在做迁移的时候需要格外的小心：我们需要明确储存在系统中每一个对象的含义及值，同时也需要确保 Stripe 在任何时候都能为用户提供服务。&lt;/p&gt;

&lt;p&gt;在这篇文章中，我们将会说明我们是如何对数以百万的订阅对象进行安全的大规模迁移。&lt;/p&gt;

&lt;h2 id=&#34;为什么迁移是困难的&#34;&gt;为什么迁移是困难的?&lt;/h2&gt;

&lt;h3 id=&#34;规模&#34;&gt;规模&lt;/h3&gt;

&lt;p&gt;Stripe 有数亿的订阅对象。运行一次涉及所有这些对象的大规模迁移对于我们的生产数据库来说意味着大量的工作。&lt;/p&gt;

&lt;p&gt;假设每个对象的迁移都要耗费 1 秒钟：以这个线性增长的方式计算，迁移数亿的对象要花掉超过三年的时间。&lt;/p&gt;

&lt;h3 id=&#34;上线时间&#34;&gt;上线时间&lt;/h3&gt;

&lt;p&gt;商家在 Stripe 上持续不断的进行交易。我们在线上进行所有的基础设施升级，而不是依赖于计划中的维护期。因为我们在迁移过程中不能只是简单的暂停这些订阅，我们必须保证所有交易的执行都可以在我们的所有服务器上 100% 运行。&lt;/p&gt;

&lt;h3 id=&#34;精确性&#34;&gt;精确性&lt;/h3&gt;

&lt;p&gt;我们的订阅表在代码库的许多不同地方都会用到。如果我们想一次性在订阅服务中修改上千行的代码，我们几乎可以确信会忽略掉一些边界条件。我们需要确保每一个服务可以继续依赖于精确的数据。&lt;/p&gt;

&lt;h2 id=&#34;在线迁移的一个模式&#34;&gt;在线迁移的一个模式&lt;/h2&gt;

&lt;p&gt;从一个表迁移百万级数据到另一个表是一件极为困难但是是许多公司不得不面对的一件事。&lt;/p&gt;

&lt;p&gt;这里有一个通用的 4 步&lt;strong&gt;双重写入模式&lt;/strong&gt;，人们经常使用像这样的模式来做线上的大规模迁移。这里是它如何工作的&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;双重写入&lt;/strong&gt; 到已经存在和新的数据库来保持它们同步。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;修改所有代码库里的读路径&lt;/strong&gt; 从新的表读数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;修改所有代码库里的写路径&lt;/strong&gt; 只写入新的表。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;移除依赖于过期数据模型的旧数据&lt;/strong&gt; 。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;我们迁移的例子-订阅&#34;&gt;我们迁移的例子: 订阅&lt;/h2&gt;

&lt;p&gt;什么是订阅以及我们为什么需要做迁移？&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://stripe.com/subscriptions&#34;&gt;Stripe 订阅&lt;/a&gt; 帮助像 &lt;a href=&#34;https://www.digitalocean.com/&#34;&gt;DigitalOcean&lt;/a&gt; 和 &lt;a href=&#34;https://www.squarespace.com/&#34;&gt;Squarespace&lt;/a&gt; 的用户建立和管理它们消费者的定期结算，在这过去的几年中，我们已经添加了许多特性去支持它们越来越复杂的账单模型，比如说多方订阅、试用、优惠券和发票。&lt;/p&gt;

&lt;p&gt;在早些时候，每个消费者对象最多可以有一个订阅。我们的消费者被当作独立的记录储存。因为消费者和订阅的映射是直接的，所以订阅是和消费者是一起储存的。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Customer
  Subscription subscription
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最终，我们意识到有些用户想要创建有多个订阅表的消费者。我们决定把 &lt;code&gt;subscription&lt;/code&gt; 字段（只支持一个订阅）转换成&lt;code&gt;subscriptions&lt;/code&gt;字段，这样我们就可以储存一个有多个活跃订阅的数组。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Customer
  array: Subscription subscriptions
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在我们添加新特性的时候，发现这个数据模型会有问题。任何对消费者订阅的改变都意味着要更新整个消费者模型，而且和订阅相关的查询也会在消费者对象中查询。所以我们决定分开储存活跃的订阅。&lt;/p&gt;

&lt;p&gt;我们重新设计了数据模型从而把订阅移到订阅表中。&lt;/p&gt;

&lt;p&gt;提醒一下⏰，我们的 4 个迁移阶段是&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;双重写入&lt;/strong&gt; 到已经存在和新的数据库来保持它们同步。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;修改所有代码库里的读路径&lt;/strong&gt; 从新的表读数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;修改所有代码库里的写路径&lt;/strong&gt; 只写入新的表.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;移除依赖于过期数据模型的旧数据&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;让我们像实践中一样来体验这4个阶段。&lt;/p&gt;

&lt;h2 id=&#34;part-1-双重写入&#34;&gt;Part 1: 双重写入&lt;/h2&gt;

&lt;p&gt;在开始迁移之前，首先我们会创建一个新的数据库表。第一步就是开始复制新消息，以便将其写入到两个储存中。我们之后会将缺失的数据回填到新的储存中，以便两个储存保存相同的信息。&lt;/p&gt;

&lt;p&gt;所有新的写入都应该更新到这两个储存。&lt;/p&gt;

&lt;p&gt;在我们的例子中，我们将所有新创建的订阅记录写到 Customers 和 Subscriptions 表中。在我们开始双重写入这两张表之前，这种额外的写入对我们生产数据库产生的潜在影响是值得我们考虑的。我们可以通过降低提高复制对象的百分比的速度来缓解性能问题，同时仔细检查运行时的指标。&lt;/p&gt;

&lt;p&gt;这时候，新创建的对象会同时存在于两个表中，而旧的数据只能在旧的表中找到。我们将会以惰性方式开始复制已经存在的订阅：每当对象更新，它们将自动被复制到新表中。这个方法让我们开始逐步转移现有的订阅。&lt;/p&gt;

&lt;p&gt;最终，我们会将所有剩余的消费者订阅数据回填到新的 Subscriptions 表中。&lt;/p&gt;

&lt;p&gt;我们需要将已经存在的订阅回填到新的 Subscriptions 表中。&lt;/p&gt;

&lt;p&gt;要在一个实时的数据库上回填一个新表其中最重要的是如何简单找到所有需要迁移的对象。通过查询数据库来查找所有对象会在生产数据库执行大量查询，这将需要很多时间。幸运的是，我们可以将这个过程分流成对我们生产数据库没影响的离线过程。我们为我们的 Hadoop 集群提供了我们的数据库快照，这使我们能够使用 &lt;a href=&#34;https://en.wikipedia.org/wiki/MapReduce&#34;&gt;MapReduce&lt;/a&gt; 通过离线、分布式的方式快速处理我们的数据。&lt;/p&gt;

&lt;p&gt;我们使用 &lt;a href=&#34;https://github.com/twitter/scalding&#34;&gt;Scalding&lt;/a&gt; 来管理我们的 MapReduce 任务。Scalding 是一个由 Scala 编写的有用的库，可以帮助我们方便的编写 MapReduce 的 Job (您可以用 10 行代码编写一个简单的 Job)。在这里，我们将会使用 Scalding 来帮助我们识别所有的订阅。我们将会遵循以下步骤：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;编写一个Scalding job，该 job 提供需要复制的所有订阅数据 ID 的列表。&lt;/li&gt;
&lt;li&gt;运行大型多线程迁移，通过一系列可以有效对我们的数据并行操作的进程来复制这些订阅。&lt;/li&gt;
&lt;li&gt;迁移完成后，再次运行 Scalding Job，以确保订阅表中没有遗漏的订阅。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;part-2-修改全部的写路径&#34;&gt;Part 2: 修改全部的写路径&lt;/h2&gt;

&lt;p&gt;现在新的和旧的数据都已经同步储存了，下一步就是开始使用新的数据储存来读取我们的全部数据。&lt;/p&gt;

&lt;p&gt;到现在为止，所有的读操作都使用已经存在的 Customers 表：我们需要将这些操作移到 Subscriptions 表中。&lt;/p&gt;

&lt;p&gt;我们需要确保从新的 Subscriptions 表中读取数据是安全的：我们的订阅数据需要保持一致性。我们将会使用 GitHub 的 &lt;a href=&#34;https://github.com/github/scientist&#34;&gt;Scientist&lt;/a&gt; 来帮助验证我们的数据读取路径。Scientist 是一个 Ruby 库可以让你运行试验并比较不同代码路径的运行结果，如果两个试验在生产中出现了不同的结果它就会提醒你。有了 Scientist，我们就可以在实时运行中生成不同结果的警告和指标。当一份试验代码路径上产生了一个错误，我们其余的应用并不会受此影响。&lt;/p&gt;

&lt;p&gt;我们将会运行以下试验:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;使用 Scientist 来同时从 Subscriptions 表和 Customers 表读取数据。&lt;/li&gt;
&lt;li&gt;如果结果并不匹配，产生一个错误来提醒我们的工程师这个结果不一致。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GitHub 的 Scientist 让我们可以运行从两张表读取数据的试验并且比较运行的结果。&lt;/p&gt;

&lt;p&gt;在我们验证所有试验都匹配上之后，我们开始从新表中读取数据。&lt;/p&gt;

&lt;p&gt;我们的试验是成功的：所有读的操作现在都是使用新的订阅表。&lt;/p&gt;

&lt;h2 id=&#34;part-3-修改所有写路径&#34;&gt;Part 3: 修改所有写路径&lt;/h2&gt;

&lt;p&gt;接下来，我们需要更新全部的写路径到我们新的 Subscriptions 储存。我们的目标是逐步推进这些变化，因此我们需要采取谨慎的策略。&lt;/p&gt;

&lt;p&gt;一直到现在 ，我们已经把数据写入到旧的储存中并且把它们复制到新的储存中：&lt;/p&gt;

&lt;p&gt;我们现在要逆转顺序：把数据写入到新的储存中之后再把它归档到旧的储存中。通过保持着两个储存的数据相互一致性，我们可以逐步更新并且仔细观察每一步的改变。&lt;/p&gt;

&lt;p&gt;在我们改变订阅的过程中最具有挑战性的部分就是重构所有的代码路径。Stripe 处理订阅操作(例如更新、划分、续订）的逻辑跨多个服务和数千行代码。&lt;/p&gt;

&lt;p&gt;能够成功重构的关键就是我们的逐步过程：我们将隔离尽可能多的代码路径到最小的单元，从而可以仔细实现每个更改。我们的两张表需要在每一步都保持一致。&lt;/p&gt;

&lt;p&gt;对于每一个代码路径，我们都需要使用一个整体的方法来确保我们所做的改变是安全的。我们不能只是用新纪录来替换老纪录：每一段的逻辑都需要仔细考虑。如果我们忽略任何情况，或许就会出现数据不一致的情况。幸运的是，我们可以运行更多的 Scientist 试验来提醒我们这个过程中任何潜在的数据不一致。&lt;/p&gt;

&lt;p&gt;我们新的简化写入路径如下所示：&lt;/p&gt;

&lt;p&gt;我们可以确保没有代码块继续使用过时的 &lt;code&gt;subscriptions&lt;/code&gt; 数组，任何对这个数组的调用都会引发错误：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Customer
  def subscriptions
    hard_assertion_failed(&amp;quot;Accessing subscriptions array on customer&amp;quot;)
  endend
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;part-4-移除旧数据&#34;&gt;Part 4: 移除旧数据&lt;/h2&gt;

&lt;p&gt;我们最终（也是最惬意）的一步是删除写入旧储存的代码并最后删除旧储存。&lt;/p&gt;

&lt;p&gt;一旦我们确信再没有代码依赖于已经过期的数据模型的 &lt;code&gt;subscriptions&lt;/code&gt; 字段，我们就再也不需要把数据写入到旧的表里了。&lt;/p&gt;

&lt;p&gt;有了这些改变，我们的代码再也不使用旧的储存，而新的表成为了我们可靠·的数据来源。&lt;/p&gt;

&lt;p&gt;我们现在可以删除所有 Customer 对象的 &lt;code&gt;subscriptions&lt;/code&gt; 数组，我们将会以惰性的方式来逐步进行删除。我们首先在每次加载订阅对象时自动清空数组，之后再运行一个最后的 Scalding job 和迁移来找到所有剩余要删除的对象。最终我们得到了所需要的模型。&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;在保持 Stripe API 的一致性的同时运行迁移是复杂的。这里有帮助我们安全运行迁移的一些点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;我们制定了一份包含 4 个阶段的迁移策略，这个策略允许我们保持生产服务器运行的同时完成数据储存的转移，而没有任何下线时间。&lt;/li&gt;
&lt;li&gt;我们使用 Hadoop 离线处理数据，这让我们可以使用 MapReduce 以并行的方式来管理高数据量，而不是依赖于生产数据库上昂贵的查询。&lt;/li&gt;
&lt;li&gt;所有做的改变都是逐步的。我们从来都没有企图一次改超过几百行的代码。&lt;/li&gt;
&lt;li&gt;我们所做的所有改变都是高度透明和可观察的。一旦任何数据出现了不一致，Scientist 试验都会提醒我们。在每一步，我们都对我们的安全迁移抱有信心。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们发现这种方法在 Stripe 上执行的许多在线迁移中都非常有效。我们希望这些实践对其他团队执行大规模迁移会有用。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Webhook 该做和不该做的: 我们在整合超过 100 个 API 中所学到的[译]</title>
      <link>https://steinliber.github.io/post/webhooks-dos-and-dont-s-what-we-learned-after-integrating-100-apis/</link>
      <pubDate>Fri, 30 Dec 2016 20:32:46 +0200</pubDate>
      
      <guid>https://steinliber.github.io/post/webhooks-dos-and-dont-s-what-we-learned-after-integrating-100-apis/</guid>
      <description>

&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;原文地址：&lt;a href=&#34;https://restful.io/webhooks-dos-and-dont-s-what-we-learned-after-integrating-100-apis-d567405a3671&#34;&gt;Webhooks do’s and dont’s: what we learned after integrating +100 APIs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;原文作者：&lt;a href=&#34;Giuliano Iacobelli&#34;&gt;Giuliano Iacobelli&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;译文出自：&lt;a href=&#34;https://github.com/xitu/gold-miner&#34;&gt;掘金翻译计划&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;译者：&lt;a href=&#34;https://github.com/steinliber&#34;&gt;steinliber&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;校对者：&lt;a href=&#34;https://github.com/xekri&#34;&gt;xekri&lt;/a&gt; , &lt;a href=&#34;https://github.com/DeadLion&#34;&gt;DeadLion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;p&gt;当现在的应用变的越来越像 API 的集合而且无服务架构获得越来越多的关注时，作为一个 API 的提供者，不应该再只是暴露传统的 REST 接口。&lt;/p&gt;

&lt;p&gt;传统 REST API 的设计是用来让你可以程序化的获取或提交内容，但在你只是想如果某些信息改变，API 再通知应用程序的情况下，传统 API 还远不够好，这还远远不是最佳的实践。如果是要实现这个的话,就需要定期轮询，而且这样还会失去扩展性。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://cdn-images-1.medium.com/max/800/1*dEmrcTajSG5A4Z_JjrGqfw.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Picture credits &lt;a href=&#34;https://medium.com/u/e6dd3fdb7c2d&#34;&gt;Lorna Mitchell&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;为了获取一小段信息，轮询 API 通常是一种既浪费又复杂的方式。一些事件或许在一段时间内只发生一次，所以你必须推断出轮询的频率。然而即使这样你也可能错过它。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Don’t call us, we’ll call you!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;好的，webhook 就是这个问题的答案.  &lt;strong&gt;webhook 就是 Web 服务使用 HTTP POST 请求为其他服务提供近实时信息的一种方式。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://cdn-images-1.medium.com/max/800/1*8t-MNjY-6rJ79rsDnZt0rA.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Picture credits &lt;a href=&#34;https://medium.com/u/e6dd3fdb7c2d&#34;&gt;Lorna Mitchell&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;一个 webhook 会在它调用时就传递数据到其它的应用，这表明你可以立即得到数据。这让使用了 webhook 的生产者和消费者都变的更有效率，如果你的 API 还不支持这些，你真应该做一些关于这方面的事。
(关注 &lt;a href=&#34;https://medium.com/u/f4fb2a348280&#34;&gt;Salesforce&lt;/a&gt; 了吗?).&lt;/p&gt;

&lt;p&gt;当涉及到 webhooks 的设计，现在并没有类似标准的 HTTP API 这样的规范。每个服务实现不同的 webhook， 从而导致许多不同的 webhooks 实现风格。&lt;/p&gt;

&lt;p&gt;我们在集成了来自 100 多个不同服务 API 后，可以说对外提供 webhook 的服务是个大“杀器”。当我们需要集成一个暴露 webhook 的服务时，这里有些建议能够帮助到我们。&lt;/p&gt;

&lt;h4 id=&#34;自我解释和一致性&#34;&gt;自我解释和一致性&lt;/h4&gt;

&lt;p&gt;一个好的 webhook 服务应该要尽可能多的提供被通知事件的信息，以及客户端执行该事件的其他信息。&lt;/p&gt;

&lt;p&gt;客户端在创建 POST 请求的时候应该包含一个 &lt;code&gt;timestamp&lt;/code&gt; 和 &lt;code&gt;webhook_id&lt;/code&gt; 字段。如果你提供的是不同类型的 webhooks，不管它们是否被发送到单个端点都应该包含一个 &lt;code&gt;type&lt;/code&gt; 属性。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://cdn-images-1.medium.com/max/600/1*Yi85OX2kNJw-bbn8O0VVQQ.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Github webhook 携带数据的示例&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://medium.com/u/d18563e4f2b9&#34;&gt;GitHub&lt;/a&gt; 非常完美的实现了以上这点。 请不要像 Instagram 或 Eventbrite 那样，只发送一个 ID 然后使用另一个 API 来解析。&lt;/p&gt;

&lt;p&gt;如果你认为你的在一次请求中发送的有效数据太多，请给我机会让它变的更轻量。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://medium.com/u/3ecae35d6d66&#34;&gt;Stripe&lt;/a&gt;’s &lt;a href=&#34;https://stripe.com/docs/api&#34;&gt;event types&lt;/a&gt; 就是一个很好的例子。&lt;/p&gt;

&lt;h4 id=&#34;允许消费者定义多个-urls&#34;&gt;允许消费者定义多个 URLs&lt;/h4&gt;

&lt;p&gt;当你构建你的 webhooks ，你应该考虑到在另一端的人必须去接收你的数据。如果只给予他们在一个网址下订阅活动的机会，那肯定不是你所可以提供的最好的开发者体验。如果我需要在不同的系统上监听相同的事件就会遇到麻烦，然后我就需要把类似 Reflector.io 的库来在系统间管理数据。&lt;a href=&#34;https://medium.com/u/ce5450a7b906&#34;&gt;Clearbit&lt;/a&gt; 请开发这样的好的 API, 并相应加快你的 webhook 开发进程。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://medium.com/u/7ca8972daf76&#34;&gt;Intercom&lt;/a&gt; 在这方面做的非常好，让你可以添加多个 URLs，并为其中的每一个都定义想监听的事件。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://cdn-images-1.medium.com/max/800/1*lGfFqT7G4x3swfm1qkxjfA.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Intercom 的 webhook 管理面板&lt;/p&gt;

&lt;h4 id=&#34;基于-ui-的订阅与基于-api-的订阅&#34;&gt;基于 UI 的订阅与基于 API 的订阅&lt;/h4&gt;

&lt;p&gt;一旦整合完成，我们应该如何处理实际订阅的创建？一些服务选择了使用 UI 来引导你完成订阅的设置，其他服务则为此提供了 API。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://cdn-images-1.medium.com/max/600/1*lQ5VTo4IF50IjaimPq-F4Q.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://medium.com/u/26d90a99f605&#34;&gt;Slack&lt;/a&gt; 两种都支持。&lt;/p&gt;

&lt;p&gt;它提供了一个精巧的UI，这使创建订阅很容易，并且它也提供了一个稳定的事件 API（仍然没有提供尽可能多的事件，比如说他们的实时消息传递 API ，但我相信他们的工作）&lt;/p&gt;

&lt;p&gt;在选择是否为 Webhooks 提供 API 时，需要记住的一件重要的事情是，订阅将以什么规模和粒度提供，以及谁将会配置它们。&lt;/p&gt;

&lt;p&gt;我发现让人感到好奇的是像 &lt;a href=&#34;https://medium.com/u/772bf2413f17&#34;&gt;MailChimp&lt;/a&gt; 这样的工具会迫使非技术的群体混淆 webhooks 配置。这些工具通过 API 提供 webhooks ，任何具有 Mailchimp 集成的第三方服务（例如 Stamplay，Zapier 或 IFTTT）都可以通过程序化的方式来实现，从而提供更好的用户体验。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://cdn-images-1.medium.com/max/600/1*EEMaCdPa63smJ3oOSpQ60w.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;要通过 API 创建新的 webhooks 订阅，你就应该像 HTTP API 中的任何其他资源一样来处理 &lt;strong&gt;订阅&lt;/strong&gt; 。&lt;/p&gt;

&lt;p&gt;最近我们在工作中发现非常好的例子是由 Box 团队在今年&lt;a href=&#34;https://blog.box.com/blog/box-webhooks/&#34;&gt;夏天&lt;/a&gt;更新的 webhook 实现。&lt;/p&gt;

&lt;h4 id=&#34;webhooks-安全&#34;&gt;webhooks 安全&lt;/h4&gt;

&lt;p&gt;一旦有人配置他的服务从你的 webhook 接收有效信息，它将会监听任何发送到端点的有效信息。&lt;/p&gt;

&lt;p&gt;如果消费者的应用程序会暴露敏感信息，那么它可以（可选）验证请求是否由你的服务生成的，而不是第三方假装是你。这种验证不是必需的，但为消息传输提供了一个额外的验证层。&lt;/p&gt;

&lt;p&gt;现在有很多方法可以实现安全性，如果你想把安全性处理放在消费者一方，你可以选择给他一个白名单来接受指定IP地址的请求，但更容易的方法是设置一个秘密令牌并验证相关信息。&lt;/p&gt;

&lt;p&gt;这方面可以从不同程度的复杂性开始做，比如说就像 Slack 或 Facebook 做的那样，在一开始使用一个纯文本共享的秘钥。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://cdn-images-1.medium.com/max/800/1*qyzDKFf4CfPwJEozGIah0w.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;至于更复杂的实现。比如说 Mandrill 对 webhook 请求进行签名，webhook POST 请求的 HTTP 头部包含了附加的&lt;code&gt;X-Mandrill-Signature&lt;/code&gt; ，这个头中将包含请求的签名。要验证 Webhook 请求，就要使用 Mandrill 相同的密钥生成签名，并将这个签名与 &lt;code&gt;X-Mandrill-Signature&lt;/code&gt; 头里的值进行比较。&lt;/p&gt;

&lt;h4 id=&#34;具有过期日期的订阅&#34;&gt;具有过期日期的订阅&lt;/h4&gt;

&lt;p&gt;现在对外提供整合了过期时间的订阅服务可能性不是很高，但可以我们可以看到这可以作为一个更常见的功能。 Microsoft Graph API 就是一个例子。除非你进行续订，否则通过 API 执行的任何订阅都将在 72 小时后过期。&lt;/p&gt;

&lt;p&gt;从数据提供商的角度来看，这是有道理的。你不想继续向可能不再运行或对你数据感兴趣的服务发送 POST 请求，但对所有真正对此感兴趣的用户来说，这是一个令人不快的体验。你是微软：如果你做不了应该做的繁重工作那又应该谁去做呢？&lt;/p&gt;

&lt;h4 id=&#34;总结&#34;&gt;总结&lt;/h4&gt;

&lt;p&gt;webhook 领域的设计仍然是分散的，但是常见的模式终究会显露出来。&lt;/p&gt;

&lt;p&gt;在 &lt;a href=&#34;https://stamplay.com/&#34;&gt;&lt;strong&gt;Stamplay&lt;/strong&gt;&lt;/a&gt; API 集成是一个问题。我们每天都面临着集成的挑战，像 Swagger ，RAML 或 API Blueprint 这样的 OpenAPI 规范并不能有所帮助，因为它们都不支持webhook 场景。&lt;/p&gt;

&lt;p&gt;所以如果你正在考虑实现 webhooks ，我邀请你想想他们的使用说明，看看例子
&lt;a href=&#34;https://medium.com/u/d18563e4f2b9&#34;&gt;GitHub&lt;/a&gt;, &lt;a href=&#34;https://medium.com/u/3ecae35d6d66&#34;&gt;Stripe&lt;/a&gt;, &lt;a href=&#34;https://medium.com/u/7ca8972daf76&#34;&gt;Intercom&lt;/a&gt; 和 &lt;a href=&#34;https://medium.com/u/272cd95a3742&#34;&gt;Slack API&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;PS. &lt;a href=&#34;https://medium.com/u/504c7870fdb6&#34;&gt;Medium&lt;/a&gt; 任何关于 webhooks 的想法？拜托，RSS 是老一套的做法啦。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;更新&lt;/strong&gt;: Medium 实际上提供了一种通过 &lt;a href=&#34;http://medium.superfeedr.com/&#34;&gt;http://medium.superfeedr.com/&lt;/a&gt; 实时通知的方式👌&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>