<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Stein&#39;s World</title>
    <link>https://steinliber.github.io/index.xml</link>
    <description>Recent content on Stein&#39;s World</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 Feb 2017 13:50:46 +0200</lastBuildDate>
    <atom:link href="https://steinliber.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>在线进行大规模的数据迁移[译]</title>
      <link>https://steinliber.github.io/post/online-migrations/</link>
      <pubDate>Fri, 24 Feb 2017 13:50:46 +0200</pubDate>
      
      <guid>https://steinliber.github.io/post/online-migrations/</guid>
      <description>

&lt;p&gt;工程师团队在构建软件时会面临一个普遍的挑战：为了支持整洁的抽象和愈加复杂的特性，他们通常需要重新设计所使用的数据模型。在生产环境中，这或许就意味着要迁移百万级的活跃对象和重构数千行的代码。&lt;/p&gt;

&lt;p&gt;Stripe 的用户期望我们的接口是可用并且一致的。这就意味着当我们在做迁移的时候需要格外的小心：我们需要明确储存在系统中每一个对象的含义及值，同时也需要确保 Stripe 在任何时候都能为用户提供服务。&lt;/p&gt;

&lt;p&gt;在这篇文章中，我们将会说明我们是如何对数以百万的订阅对象进行安全的大规模迁移。&lt;/p&gt;

&lt;h2 id=&#34;为什么迁移是困难的&#34;&gt;为什么迁移是困难的?&lt;/h2&gt;

&lt;h3 id=&#34;规模&#34;&gt;规模&lt;/h3&gt;

&lt;p&gt;Stripe 有数亿的订阅对象。运行一次涉及所有这些对象的大规模迁移对于我们的生产数据库来说意味着大量的工作。&lt;/p&gt;

&lt;p&gt;假设每个对象的迁移都要耗费 1 秒钟：以这个线性增长的方式计算，迁移数亿的对象要花掉超过三年的时间。&lt;/p&gt;

&lt;h3 id=&#34;上线时间&#34;&gt;上线时间&lt;/h3&gt;

&lt;p&gt;商家在 Stripe 上持续不断的进行交易。我们在线上进行所有的基础设施升级，而不是依赖于计划中的维护期。因为我们在迁移过程中不能只是简单的暂停这些订阅，我们必须保证所有交易的执行都可以在我们的所有服务器上 100% 运行。&lt;/p&gt;

&lt;h3 id=&#34;精确性&#34;&gt;精确性&lt;/h3&gt;

&lt;p&gt;我们的订阅表在代码库的许多不同地方都会用到。如果我们想一次性在订阅服务中修改上千行的代码，我们几乎可以确信会忽略掉一些边界条件。我们需要确保每一个服务可以继续依赖于精确的数据。&lt;/p&gt;

&lt;h2 id=&#34;在线迁移的一个模式&#34;&gt;在线迁移的一个模式&lt;/h2&gt;

&lt;p&gt;从一个表迁移百万级数据到另一个表是一件极为困难但是是许多公司不得不面对的一件事。&lt;/p&gt;

&lt;p&gt;这里有一个通用的 4 步&lt;strong&gt;双重写入模式&lt;/strong&gt;，人们经常使用像这样的模式来做线上的大规模迁移。这里是它如何工作的&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;双重写入&lt;/strong&gt; 到已经存在和新的数据库来保持它们同步。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;修改所有代码库里的读路径&lt;/strong&gt; 从新的表读数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;修改所有代码库里的写路径&lt;/strong&gt; 只写入新的表。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;移除依赖于过期数据模型的旧数据&lt;/strong&gt; 。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;我们迁移的例子-订阅&#34;&gt;我们迁移的例子: 订阅&lt;/h2&gt;

&lt;p&gt;什么是订阅以及我们为什么需要做迁移？&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://stripe.com/subscriptions&#34;&gt;Stripe 订阅&lt;/a&gt; 帮助像 &lt;a href=&#34;https://www.digitalocean.com/&#34;&gt;DigitalOcean&lt;/a&gt; 和 &lt;a href=&#34;https://www.squarespace.com/&#34;&gt;Squarespace&lt;/a&gt; 的用户建立和管理它们消费者的定期结算，在这过去的几年中，我们已经添加了许多特性去支持它们越来越复杂的账单模型，比如说多方订阅、试用、优惠券和发票。&lt;/p&gt;

&lt;p&gt;在早些时候，每个消费者对象最多可以有一个订阅。我们的消费者被当作独立的记录储存。因为消费者和订阅的映射是直接的，所以订阅是和消费者是一起储存的。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Customer
  Subscription subscription
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最终，我们意识到有些用户想要创建有多个订阅表的消费者。我们决定把 &lt;code&gt;subscription&lt;/code&gt; 字段（只支持一个订阅）转换成&lt;code&gt;subscriptions&lt;/code&gt;字段，这样我们就可以储存一个有多个活跃订阅的数组。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Customer
  array: Subscription subscriptions
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在我们添加新特性的时候，发现这个数据模型会有问题。任何对消费者订阅的改变都意味着要更新整个消费者模型，而且和订阅相关的查询也会在消费者对象中查询。所以我们决定分开储存活跃的订阅。&lt;/p&gt;

&lt;p&gt;我们重新设计了数据模型从而把订阅移到订阅表中。&lt;/p&gt;

&lt;p&gt;提醒一下⏰，我们的 4 个迁移阶段是&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;双重写入&lt;/strong&gt; 到已经存在和新的数据库来保持它们同步。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;修改所有代码库里的读路径&lt;/strong&gt; 从新的表读数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;修改所有代码库里的写路径&lt;/strong&gt; 只写入新的表.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;移除依赖于过期数据模型的旧数据&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;让我们像实践中一样来体验这4个阶段。&lt;/p&gt;

&lt;h2 id=&#34;part-1-双重写入&#34;&gt;Part 1: 双重写入&lt;/h2&gt;

&lt;p&gt;在开始迁移之前，首先我们会创建一个新的数据库表。第一步就是开始复制新消息，以便将其写入到两个储存中。我们之后会将缺失的数据回填到新的储存中，以便两个储存保存相同的信息。&lt;/p&gt;

&lt;p&gt;所有新的写入都应该更新到这两个储存。&lt;/p&gt;

&lt;p&gt;在我们的例子中，我们将所有新创建的订阅记录写到 Customers 和 Subscriptions 表中。在我们开始双重写入这两张表之前，这种额外的写入对我们生产数据库产生的潜在影响是值得我们考虑的。我们可以通过降低提高复制对象的百分比的速度来缓解性能问题，同时仔细检查运行时的指标。&lt;/p&gt;

&lt;p&gt;这时候，新创建的对象会同时存在于两个表中，而旧的数据只能在旧的表中找到。我们将会以惰性方式开始复制已经存在的订阅：每当对象更新，它们将自动被复制到新表中。这个方法让我们开始逐步转移现有的订阅。&lt;/p&gt;

&lt;p&gt;最终，我们会将所有剩余的消费者订阅数据回填到新的 Subscriptions 表中。&lt;/p&gt;

&lt;p&gt;我们需要将已经存在的订阅回填到新的 Subscriptions 表中。&lt;/p&gt;

&lt;p&gt;要在一个实时的数据库上回填一个新表其中最重要的是如何简单找到所有需要迁移的对象。通过查询数据库来查找所有对象会在生产数据库执行大量查询，这将需要很多时间。幸运的是，我们可以将这个过程分流成对我们生产数据库没影响的离线过程。我们为我们的 Hadoop 集群提供了我们的数据库快照，这使我们能够使用 &lt;a href=&#34;https://en.wikipedia.org/wiki/MapReduce&#34;&gt;MapReduce&lt;/a&gt; 通过离线、分布式的方式快速处理我们的数据。&lt;/p&gt;

&lt;p&gt;我们使用 &lt;a href=&#34;https://github.com/twitter/scalding&#34;&gt;Scalding&lt;/a&gt; 来管理我们的 MapReduce 任务。Scalding 是一个由 Scala 编写的有用的库，可以帮助我们方便的编写 MapReduce 的 Job (您可以用 10 行代码编写一个简单的 Job)。在这里，我们将会使用 Scalding 来帮助我们识别所有的订阅。我们将会遵循以下步骤：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;编写一个Scalding job，该 job 提供需要复制的所有订阅数据 ID 的列表。&lt;/li&gt;
&lt;li&gt;运行大型多线程迁移，通过一系列可以有效对我们的数据并行操作的进程来复制这些订阅。&lt;/li&gt;
&lt;li&gt;迁移完成后，再次运行 Scalding Job，以确保订阅表中没有遗漏的订阅。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;part-2-修改全部的写路径&#34;&gt;Part 2: 修改全部的写路径&lt;/h2&gt;

&lt;p&gt;现在新的和旧的数据都已经同步储存了，下一步就是开始使用新的数据储存来读取我们的全部数据。&lt;/p&gt;

&lt;p&gt;到现在为止，所有的读操作都使用已经存在的 Customers 表：我们需要将这些操作移到 Subscriptions 表中。&lt;/p&gt;

&lt;p&gt;我们需要确保从新的 Subscriptions 表中读取数据是安全的：我们的订阅数据需要保持一致性。我们将会使用 GitHub 的 &lt;a href=&#34;https://github.com/github/scientist&#34;&gt;Scientist&lt;/a&gt; 来帮助验证我们的数据读取路径。Scientist 是一个 Ruby 库可以让你运行试验并比较不同代码路径的运行结果，如果两个试验在生产中出现了不同的结果它就会提醒你。有了 Scientist，我们就可以在实时运行中生成不同结果的警告和指标。当一份试验代码路径上产生了一个错误，我们其余的应用并不会受此影响。&lt;/p&gt;

&lt;p&gt;我们将会运行以下试验:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;使用 Scientist 来同时从 Subscriptions 表和 Customers 表读取数据。&lt;/li&gt;
&lt;li&gt;如果结果并不匹配，产生一个错误来提醒我们的工程师这个结果不一致。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GitHub 的 Scientist 让我们可以运行从两张表读取数据的试验并且比较运行的结果。&lt;/p&gt;

&lt;p&gt;在我们验证所有试验都匹配上之后，我们开始从新表中读取数据。&lt;/p&gt;

&lt;p&gt;我们的试验是成功的：所有读的操作现在都是使用新的订阅表。&lt;/p&gt;

&lt;h2 id=&#34;part-3-修改所有写路径&#34;&gt;Part 3: 修改所有写路径&lt;/h2&gt;

&lt;p&gt;接下来，我们需要更新全部的写路径到我们新的 Subscriptions 储存。我们的目标是逐步推进这些变化，因此我们需要采取谨慎的策略。&lt;/p&gt;

&lt;p&gt;一直到现在 ，我们已经把数据写入到旧的储存中并且把它们复制到新的储存中：&lt;/p&gt;

&lt;p&gt;我们现在要逆转顺序：把数据写入到新的储存中之后再把它归档到旧的储存中。通过保持着两个储存的数据相互一致性，我们可以逐步更新并且仔细观察每一步的改变。&lt;/p&gt;

&lt;p&gt;在我们改变订阅的过程中最具有挑战性的部分就是重构所有的代码路径。Stripe 处理订阅操作(例如更新、划分、续订）的逻辑跨多个服务和数千行代码。&lt;/p&gt;

&lt;p&gt;能够成功重构的关键就是我们的逐步过程：我们将隔离尽可能多的代码路径到最小的单元，从而可以仔细实现每个更改。我们的两张表需要在每一步都保持一致。&lt;/p&gt;

&lt;p&gt;对于每一个代码路径，我们都需要使用一个整体的方法来确保我们所做的改变是安全的。我们不能只是用新纪录来替换老纪录：每一段的逻辑都需要仔细考虑。如果我们忽略任何情况，或许就会出现数据不一致的情况。幸运的是，我们可以运行更多的 Scientist 试验来提醒我们这个过程中任何潜在的数据不一致。&lt;/p&gt;

&lt;p&gt;我们新的简化写入路径如下所示：&lt;/p&gt;

&lt;p&gt;我们可以确保没有代码块继续使用过时的 &lt;code&gt;subscriptions&lt;/code&gt; 数组，任何对这个数组的调用都会引发错误：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Customer
  def subscriptions
    hard_assertion_failed(&amp;quot;Accessing subscriptions array on customer&amp;quot;)
  endend
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;part-4-移除旧数据&#34;&gt;Part 4: 移除旧数据&lt;/h2&gt;

&lt;p&gt;我们最终（也是最惬意）的一步是删除写入旧储存的代码并最后删除旧储存。&lt;/p&gt;

&lt;p&gt;一旦我们确信再没有代码依赖于已经过期的数据模型的 &lt;code&gt;subscriptions&lt;/code&gt; 字段，我们就再也不需要把数据写入到旧的表里了。&lt;/p&gt;

&lt;p&gt;有了这些改变，我们的代码再也不使用旧的储存，而新的表成为了我们可靠·的数据来源。&lt;/p&gt;

&lt;p&gt;我们现在可以删除所有 Customer 对象的 &lt;code&gt;subscriptions&lt;/code&gt; 数组，我们将会以惰性的方式来逐步进行删除。我们首先在每次加载订阅对象时自动清空数组，之后再运行一个最后的 Scalding job 和迁移来找到所有剩余要删除的对象。最终我们得到了所需要的模型。&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;在保持 Stripe API 的一致性的同时运行迁移是复杂的。这里有帮助我们安全运行迁移的一些点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;我们制定了一份包含 4 个阶段的迁移策略，这个策略允许我们保持生产服务器运行的同时完成数据储存的转移，而没有任何下线时间。&lt;/li&gt;
&lt;li&gt;我们使用 Hadoop 离线处理数据，这让我们可以使用 MapReduce 以并行的方式来管理高数据量，而不是依赖于生产数据库上昂贵的查询。&lt;/li&gt;
&lt;li&gt;所有做的改变都是逐步的。我们从来都没有企图一次改超过几百行的代码。&lt;/li&gt;
&lt;li&gt;我们所做的所有改变都是高度透明和可观察的。一旦任何数据出现了不一致，Scientist 试验都会提醒我们。在每一步，我们都对我们的安全迁移抱有信心。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们发现这种方法在 Stripe 上执行的许多在线迁移中都非常有效。我们希望这些实践对其他团队执行大规模迁移会有用。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Python 中的协程</title>
      <link>https://steinliber.github.io/post/async/</link>
      <pubDate>Mon, 23 Jan 2017 13:50:46 +0200</pubDate>
      
      <guid>https://steinliber.github.io/post/async/</guid>
      <description>&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;并发描述的是一个程序是否被分成了多个可执行片段，使得每个片段都可以独立运行,不同执行片段通过通信来进行协调。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;并发与并行
首先应该明确的一点就是并发和并行的概念.并发是程序级的概念，描述的是一段程序里面可执行片段的多少，所以在程序中使用进程，线程，协程都能提高程序的并发性。而并行描述的是程序的计算过程，在同一时间内，该程序同时执行多个可执行片段。现代操作系统中的最小可执行单位是线程，你创建一个进程，操作系统实际执行单位也是该进程中的线程，也就是说只要你的计算机CPU是有多核的，而且你的程序被分成了多个线程或者进程，那每个CPU都会执行其中的一个线程 （没别的任务的情况下）这时候程序就是并行的。而协程只是一个线程中的一部分执行片段，所以单纯的使用协程并不能提高程序的并行性，只能提高单核CPU的并发性。下图表明在双核CPU的计算机下多线程和多协程的运行情况（python中因为GIL的存在是无法做到多线程的，图中只是理想情况下-。-）。
&lt;img src=&#34;http://upload-images.jianshu.io/upload_images/1682167-b082f5565ca29ce4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&#34; alt=&#34;多线程多协程代码的执行情况&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;协程的应用场景
要了解 协程，首先要知道当cpu处理系统io操作时，会等待这些操作的完成，你可知道这短短的等待时间cpu可以执行多少命令，下面是node.js的创始人在一次演讲上展示的图。
&lt;img src=&#34;http://upload-images.jianshu.io/upload_images/1682167-1473da0167ff5264.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&#34; alt=&#34;现在的电脑从不同的储存设备中读取数据的延迟(最后一列只是类比)&#34; /&gt;
当今的计算机cpu普遍性能可以达到2000000000次/秒，简单计算下从硬盘中取数据会让cpu什么都不干0.0025秒，那段时间本来可以执行5000000条指令啊-_-。于是就诞生了两种方法来防止io的阻塞。
(1) 为每个会阻塞的操作单独创建一个线程，这样你取你的，我运行我的，就可以提高cpu的利用率
(2)把每个会阻塞的操作变成一个异步调用，我先跑我的，等你取完了通知我再收拾你
线程的切换有个问题，切换线程消耗的资源多，还有锁。其实最重要的是python因为gil的存在，对线程的支持十分有限。
在第二种方法中可以分为异步回调和协程两种方式。这两者最大的区别是协程在内存中维护自身的运行状态和上下文，这样程序的逻辑流表现起来就非常简单，而异步回调则是通过在调用函数中注册回调函数，调用函数的运行状态通过回调函数返回。所以一般来说回调函数的实现都会比协程复杂（关于回调具体可以看&lt;a href=&#34;http://blog.ometer.com/2011/07/24/callbacks-synchronous-and-asynchronous/）&#34;&gt;http://blog.ometer.com/2011/07/24/callbacks-synchronous-and-asynchronous/）&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;python中的协程
在python中协程的实现是通过yield来实现的，有些同学可能知道yield是用来把函数变成生成器的却不知道它也可以用于协程。其实仔细一想你就知道，yield命令其实会保存当前函数的上下文，然后返回一个数值给调用它的函数。再想想上面的协程实现，嘿嘿，懂了吧。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;总的来说，协程作为一个程序级的实现，优化了程序io的性能，同时把异步回调的实现变成了同步，再加上python中asyncio库的支持，非常推荐大家去学习下。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>elasticsearch 使用中的坑</title>
      <link>https://steinliber.github.io/post/elasticsearch_fill/</link>
      <pubDate>Tue, 17 Jan 2017 13:50:46 +0200</pubDate>
      
      <guid>https://steinliber.github.io/post/elasticsearch_fill/</guid>
      <description>&lt;p&gt;在Es的使用过程中，会遇到许多的坑，在这里总结下我所遇到的一些问题和解决方法。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Es重建索引
Es的索引不像mysql等数据库那样可以方便的更改和删除字段，所以如果ES中涉及到字段的变更，就需要重建索引。在Es中存在大量数据的情况下怎样才能做到ES保持正常服务的同时又能建立新的索引？
（1）首先我们要创建一个alias指向当前索引，所有对当前索引的操作都通过alias（相当于软连接）
（2）然后我们需要创建一个名字不同的索引（最好带上版本号）并创建自己所需要的映射关系
（3）使用Es提供的reindex将现有索引的数据全部导入到新的索引中
（4）将（1）中的假名指向新索引，这样所有的请求都会有新索引来处理
（5）删除旧的索引
上述方法在索引存在大量数据reindex时会对性能产生较大影响，还有的方法就是在索引中不管需要更改的字段，直接创建新的字段，在程序中控制返回的结果，这样会使程序变得比较复杂但重建索引时对Es性能影响不大。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Es近实时搜索
Es处于性能的考虑，默认会每隔一秒钟将内存中的段保存到硬盘中，这时候保存的记录才会被搜索到，这在现实中影响不是很大，但在写测试的时候如果保存了记录却搜索不到，总不能每次都等一秒钟再搜索把。这时候可以用Es的flush将数据手动刷新到硬盘，这样数据就可以搜索到了
、&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;EsRejectedExecutionException的问题
Es中处理数据时会将请求的数据在队列中保存起来，当请求的数据数量过多，es的处理速度跟不上时，es要处理的数据会超过队列的长度，这些多出来的数据就会返EsRejectedExecutionException异常。在我的Mac上（8G内存，I5处理器）在Es上建立80万的数据，有1万个数据因为EsRejectedExecutionException而丢失。处理这个问题有两种解决方法&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;提高本机的性能，对es进行相关配置
Es处理的速度如果能高于请求建立索引的速度，那自然不会有这个问题。Es中默认的相关配置比较低，我们可以进行一定的配置来提高处理性能，如可以在环境变量中设置ES_MIN_MEM=8g，ES_MAX_MEM=8g，java我也不是很懂，估计是增大es可以使用的系统内存来提高运行速度&lt;/li&gt;
&lt;li&gt;上面的方法毕竟治标不治本，在部署环境下，不同的机子可能会有不同的性能，所以需要我们该想办法把被EsRejectedExecutionException的记录重新建立索引，实现的python代码如下所示&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;   actions = self._build_elastic_actions(elas_indexs)
         success_num, err_items = bulk(
             client=self.es,
             actions=(#要在es中保存的数据，可迭代的都行),
             chunk_size=200,
             raise_on_error=False,
             raise_on_exception=False
         )
         # 处理es拒绝服务的情况
         reject_es_data_id = [error[&#39;index&#39;][&#39;_id&#39;] for error in err_items
                              if error[&#39;index&#39;][&#39;status&#39;] == 429]
         try_time = 0
         while len(reject_es_data_id) &amp;gt; 0 and try_time &amp;lt; 5:
             time.sleep(5)
             records = Record.objects.filter(id__in=reject_es_data_id)
             re_success_num, re_error_items = bulk(
                 client=self.es,
                 actions=(#要重建的索引),
                 chunk_size=200,
                 raise_on_error=False,
                 raise_on_exception=False
             )
             reject_es_data_id = [error[&#39;index&#39;][&#39;_id&#39;] for error in err_items
                                  if error[&#39;index&#39;][&#39;status&#39;] == 429]
             success_num += re_success_num
             try_time += 1
         error_items = [error for error in err_items if error[&#39;index&#39;][&#39;status&#39;] != 429]
         error_items.extend(re_error_items)
         return success_num, error_items
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;基本思想就是每次bulk创建es的索引，检测返回的错误中有没有因为EsRejectedExecutionException异常而索引失败的，如果有就进入一个循环，在循环中休息5秒再创建被拒绝的索引，这样循环5次，还是没创建的话就退出创建剩下的。在这里我在es中创建和本地数据库id一样的记录，所以可以通过id来重新建索引。基本上就是这个意思，剩下什么错误的记录什么的实现起来都很简单。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Es的默认模版
如果你是动态创建索引的话（也就是说不创建字段的映射关系，由Es自动判断字段的类型）对于有些字段，你可能就想要这个类型，而Es却会把他创建为另一个类型。比如说你有个字段keywords，这个字段当然不能被分词，而es一般会将字符串都保存为分词的形式，这就不符合我们的需求了。
还好Es中提供了默认模版的机制，可以指定特定索引哪些字段储存为什么类型&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Es的搜索结果数量
在默认情况下，Es只会返回搜索结果的前10项，可以通过分页来获取后面的内容，但如果分页太深或者返回的结果太多，可能会导致性能问题。因为当我们请求结果的第一页（结果1到10）时，每个分片产生自己最顶端10个结果然后返回它们给请求节点，它再排序这所有的50个结果以选出顶端的10个结果。而如果我们请求第1000页时，得到的结果是10001到10010的数据。工作方式都相同，不同的是每个分片都必须产生顶端的10010个结果。然后请求节点排序这50050个结果并丢弃了剩余的50040个。当真有这种需求时，可以使用Es的scroll来进行搜索，它会在Es中记录上次搜寻的位置，我们就可以持续的从Es中拉数据。也可以用scan来禁用排序，只要有分片中有结果就返回。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://steinliber.github.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://steinliber.github.io/about/</guid>
      <description>

&lt;h3 id=&#34;book&#34;&gt;book&lt;/h3&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://steinliber.github.io/booklist/test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://steinliber.github.io/booklist/test/</guid>
      <description>

&lt;h2 id=&#34;test&#34;&gt;test&lt;/h2&gt;
</description>
    </item>
    
  </channel>
</rss>